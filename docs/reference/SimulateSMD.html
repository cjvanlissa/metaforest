<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Simulates a meta-analytic dataset — SimulateSMD • metaforest</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />

<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="Simulates a meta-analytic dataset — SimulateSMD" />
<meta property="og:description" content="This function simulates a meta-analytic dataset based on the random-effects
model. The simulated effect size is Hedges' G, an estimator of the
Standardized Mean Difference (Hedges, 1981; Li, Dusseldorp, &amp;amp; Meulman, 2017).
The functional form of the model can be specified, and moderators can be
either normally distributed or Bernoulli-distributed. See Van Lissa, in
preparation, for a detailed explanation of the simulation procedure." />
<meta name="twitter:card" content="summary" />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">metaforest</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.3.4</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/Introduction_to_metaforest.html">Introduction to metaforest</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Simulates a meta-analytic dataset</h1>
    
    <div class="hidden name"><code>SimulateSMD.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>This function simulates a meta-analytic dataset based on the random-effects
model. The simulated effect size is Hedges' G, an estimator of the
Standardized Mean Difference (Hedges, 1981; Li, Dusseldorp, &amp; Meulman, 2017).
The functional form of the model can be specified, and moderators can be
either normally distributed or Bernoulli-distributed. See Van Lissa, in
preparation, for a detailed explanation of the simulation procedure.</p>
    </div>

    <pre class="usage"><span class='fu'>SimulateSMD</span>(<span class='kw'>k_train</span> <span class='kw'>=</span> <span class='fl'>20</span>, <span class='kw'>k_test</span> <span class='kw'>=</span> <span class='fl'>100</span>, <span class='kw'>mean_n</span> <span class='kw'>=</span> <span class='fl'>40</span>, <span class='kw'>es</span> <span class='kw'>=</span> <span class='fl'>0.5</span>,
  <span class='kw'>tau2</span> <span class='kw'>=</span> <span class='fl'>0.04</span>, <span class='kw'>moderators</span> <span class='kw'>=</span> <span class='fl'>5</span>, <span class='kw'>distribution</span> <span class='kw'>=</span> <span class='st'>"normal"</span>, <span class='kw'>model</span> <span class='kw'>=</span> <span class='no'>es</span>
  * <span class='no'>x</span>[, <span class='fl'>1</span>])</pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>k_train</th>
      <td><p>Atomic integer. The number of studies in the training dataset.
Defaults to 20.</p></td>
    </tr>
    <tr>
      <th>k_test</th>
      <td><p>Atomic integer. The number of studies in the testing dataset.
Defaults to 100.</p></td>
    </tr>
    <tr>
      <th>mean_n</th>
      <td><p>Atomic integer. The mean sample size of each simulated study in
the meta-analytic dataset. Defaults to 40. For each simulated study, the
sample size n is randomly drawn from a normal distribution with mean mean_n,
and sd mean_n/3.</p></td>
    </tr>
    <tr>
      <th>es</th>
      <td><p>Atomic numeric vector. The effect size, also known as beta, used in
the model statement. Defaults to .5.</p></td>
    </tr>
    <tr>
      <th>tau2</th>
      <td><p>Atomic numeric vector. The residual heterogeneity. For a range of
realistic values encountered in psychological research, see Van Erp,
Verhagen, Grasman, &amp; Wagenmakers, 2017. Defaults to 0.04.</p></td>
    </tr>
    <tr>
      <th>moderators</th>
      <td><p>Atomic integer. The number of moderators to simulate for
each study. Make sure that the number of moderators to be simulated is at
least as large as the number of moderators referred to in the model
parameter. Internally, the matrix of moderators is referred to as "x".
Defaults to 5.</p></td>
    </tr>
    <tr>
      <th>distribution</th>
      <td><p>Atomic character. The distribution of the moderators.
Can be set to either "normal" or "bernoulli". Defaults to "normal".</p></td>
    </tr>
    <tr>
      <th>model</th>
      <td><p>Expression. An expression to specify the model from which to
simulate the mean true effect size, mu. This formula may use the terms "es"
(referring to the es parameter of the call to SimulateSMD), and "x[, ]"
(referring to the matrix of moderators, x). Thus, to specify that the mean
effect size, mu, is a function of the effect size and the first moderator,
one would pass the value <code>model = es * x[ , 1]</code>.
Defaults to es * x[ , 1].</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>List of length 4. The "training" element of this list is a data.frame
with k_train rows. The columns are the variance of the effect size, vi; the
effect size, yi, and the moderators, X. The "testing" element of this list is
a data.frame with k_test rows. The columns are the effect size, yi, and the
moderators, X. The "housekeeping" element of this list is a data.frame with
k_train + k_test rows. The columns are n, the sample size n for each
simulated study; mu_i, the mean true effect size for each simulated study;
and theta_i, the true effect size for each simulated study.</p>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span>(<span class='fl'>8</span>)
<span class='fu'>SimulateSMD</span>()</div><div class='output co'>#&gt; $training
#&gt;            vi          yi         X1          X2           X3         X4
#&gt; 1  0.10203008 -0.29398896 -1.1444094 -1.04043881  0.062535228  1.0148301
#&gt; 2  0.08522324 -1.05004992 -1.7215353  0.02465913  0.231113964 -0.8321755
#&gt; 3  0.11681403 -0.56288787 -0.3696855  0.86220033  1.517608501 -1.4727851
#&gt; 4  0.14655758  1.33340253  1.8220755  0.70828681 -0.498742894  0.4537334
#&gt; 5  0.07785210  0.18586277  0.4775898 -0.63656810  0.004252849  0.6631271
#&gt; 6  0.11685791  1.10151909  0.1405485  0.90875200  0.359516304 -0.7153895
#&gt; 7  0.10640890 -0.64747180 -1.7260245 -0.58273245  2.082965890  2.0207644
#&gt; 8  0.14712820 -0.38464515  0.2765317  0.08109775 -1.408034082  1.9224919
#&gt; 9  0.38000714  0.17596855 -1.3627597 -0.04364549  1.217850494 -0.5379136
#&gt; 10 0.11878046 -0.01505409  0.8354238  0.27538614  0.721791139 -1.1210611
#&gt; 11 0.15549760  1.32530940  2.2256232  1.03476676 -0.201646518 -0.7519621
#&gt; 12 0.08957362  0.40904980  0.1722670 -0.44401335  0.095368307 -0.4055921
#&gt; 13 0.11684822 -1.73838165 -1.5005928 -1.34238940 -2.032627280 -0.1743360
#&gt; 14 0.18469118 -0.84998262 -1.3466174 -0.16337964 -1.775771585  0.9972979
#&gt; 15 0.11703169 -1.29509008 -2.4010823 -0.24919870  0.066025885  0.5076123
#&gt; 16 0.12790515  0.31764430  0.7935204  0.66247074 -1.224103992 -0.9695288
#&gt; 17 0.06828162  0.63264296  0.4438913  0.64397076  1.578454567  0.2136013
#&gt; 18 0.10985373  0.51095349  0.5038261 -0.85192796 -0.204568006 -0.6238114
#&gt; 19 0.07929649  1.31225812  1.4280847 -0.72472537  0.413325429  0.3302807
#&gt; 20 0.10629565  0.06994284 -1.8320869 -0.13801556 -0.355544375 -1.3008866
#&gt;             X5
#&gt; 1   0.88819728
#&gt; 2   0.29270972
#&gt; 3   0.31683564
#&gt; 4  -2.02425302
#&gt; 5  -0.91530048
#&gt; 6  -0.34304121
#&gt; 7  -0.61830454
#&gt; 8   1.96917331
#&gt; 9   1.28234666
#&gt; 10  1.21800036
#&gt; 11 -1.27702516
#&gt; 12  2.08310267
#&gt; 13 -0.65815868
#&gt; 14 -0.34382308
#&gt; 15  0.74423183
#&gt; 16 -1.32233177
#&gt; 17  0.39138003
#&gt; 18 -0.09488615
#&gt; 19  1.13265525
#&gt; 20  0.46624137
#&gt; 
#&gt; $testing
#&gt;              yi          X1           X2          X3          X4           X5
#&gt; 21   0.66822969  1.34278280 -0.345707310  1.57818995 -0.44913981  0.705276551
#&gt; 22   1.14976311  2.43894434  0.407881830 -1.09289061  0.02348950 -1.346451232
#&gt; 23  -0.08996973  0.67693611 -0.542383594 -0.76616169  0.32860881  1.606175428
#&gt; 24  -0.85126944 -1.96898063 -2.233980278 -2.44080992 -0.65851847  2.978035548
#&gt; 25  -0.21095617  0.08038142  1.317620135 -0.66787498 -0.69390119  0.889280799
#&gt; 26  -0.28505282 -0.70476923  0.421883928 -0.87779243 -1.02011480 -0.364122280
#&gt; 27   1.42561465  0.59725232 -0.742518989 -0.24948742 -1.10058841  0.054619107
#&gt; 28   0.22666273  0.79577963  0.246548388 -0.91454381 -1.61812166 -0.589375171
#&gt; 29  -1.02761756 -1.03083607 -0.534765887  0.08087580  2.14679976  0.050225736
#&gt; 30   0.59061935 -0.41952683 -1.375543934 -0.08288448 -0.71783589  2.617582843
#&gt; 31  -0.01700093  0.16009113 -0.410783842 -0.40642879  0.89826920  0.627148220
#&gt; 32   0.03276619 -0.56448033  1.072109345  0.69900714 -1.15007197 -0.827227458
#&gt; 33   0.03926500  0.22750654  0.944193458  0.47244670 -1.04069937  0.504060258
#&gt; 34   0.41097112  0.25707888 -0.660594907  0.98195504 -0.06291613 -0.394589512
#&gt; 35  -0.49098768 -0.33770080  0.463225218 -1.44548947  1.37773115  0.357938059
#&gt; 36  -0.41254464  0.30457246 -0.833497207  0.01650441  0.62319204 -0.115376387
#&gt; 37   0.72602926  0.72443709 -1.656108832 -0.19116183 -0.69531851  0.680534148
#&gt; 38  -0.12909938 -0.68517330 -0.242947018  0.60615056  0.34736006  0.377851898
#&gt; 39  -0.15842320  0.66148590 -0.734829314  1.11059186 -1.66093486  0.386261629
#&gt; 40   0.49299914  1.72541962  0.288050068 -0.02910979  1.22541007  0.549553058
#&gt; 41   0.50610349  0.32134570 -2.519865202 -0.29233821  1.04911272  0.613320135
#&gt; 42  -1.00525772  0.57631589  0.559240717  1.47869193  0.07042518 -0.795713800
#&gt; 43  -0.67371732 -1.40999218 -0.370775118  0.73176907  0.34117199 -1.490813982
#&gt; 44  -0.50289312 -0.99550207 -0.246350631 -1.19898977 -0.45694682 -0.769902613
#&gt; 45   0.50431041  1.56029895 -1.068533578  1.51577158  0.36241300  1.625447491
#&gt; 46   0.88685955  0.20359400  0.188859634 -0.36821179  0.43088979  0.903666849
#&gt; 47  -0.70385005 -0.38763480 -0.700101046 -0.61153291 -3.28193174 -0.938239707
#&gt; 48   1.11709753  0.91961483 -0.054871878 -0.99407239  0.07959148 -0.863328748
#&gt; 49  -0.26009914 -0.37973893  0.004724072  0.22384503  0.28338913 -0.012054345
#&gt; 50   0.47557698  0.74424525  0.513744294  1.24460620 -1.13800059 -1.018069491
#&gt; 51  -0.26393460 -1.18318210 -0.232082803 -2.14666505  0.55833481 -1.304871448
#&gt; 52   0.36147994  0.27641906 -0.503803381  0.52658047  1.45478371 -0.907842475
#&gt; 53   0.07970255 -0.35621772  0.931147030 -0.13259284  0.91997026  0.045246555
#&gt; 54   0.32843947  0.98772386  0.866682884 -0.36330720 -2.45861485  1.591761639
#&gt; 55   0.37604723 -0.26723365 -1.615076668 -0.89040754  1.35749161  0.146493228
#&gt; 56   0.24895657  0.48002729 -0.414854751 -0.54416473 -0.73312796 -0.463292606
#&gt; 57   1.06896275  0.76742274  0.295879429 -0.46053733  0.38481593  0.236661956
#&gt; 58   0.01179023  0.93944209 -0.501413917 -0.19810448  0.92773032  0.664210399
#&gt; 59   0.24653265 -1.05321259  0.168396365 -0.05398731 -1.23938949  0.629995102
#&gt; 60   0.02307407  1.01361777 -1.484505096  0.06713632  1.73655423 -0.219841525
#&gt; 61  -0.25616540 -1.25417324 -0.935164736  1.37062115  0.46932808  0.001456405
#&gt; 62   0.02411692 -0.38058363 -1.318323265 -1.71261554  0.27094446 -0.450508307
#&gt; 63  -0.74419979  0.20908883 -0.843522645 -1.54077184 -0.66946378 -0.418097081
#&gt; 64   0.26424977 -0.12475618 -0.180237064  1.42855685  0.54643929  0.338293573
#&gt; 65   1.09889987  2.18637793 -1.473517194 -1.19629850  0.29537750 -0.393182816
#&gt; 66   0.28142974  0.08202324  0.296855110  0.88030339 -1.13881229 -0.354461946
#&gt; 67   1.66695308  2.11210205  0.483606325 -1.68208244  1.29022620 -1.206672296
#&gt; 68   0.77291745  1.03434270  0.068466459  1.69888450 -2.22984375 -0.412220453
#&gt; 69  -0.11320584 -0.19817321  0.288832146 -0.15496161  1.28430248  0.386628349
#&gt; 70  -0.54707185 -1.03922958  1.314781376 -1.27400097 -1.41318801 -0.619818844
#&gt; 71  -0.36965484 -0.13366410 -0.295572687 -0.58194548 -0.69842091  1.081208993
#&gt; 72  -0.53441321 -0.58203619 -0.064578436 -0.43066068  0.82325010 -1.678908961
#&gt; 73   0.03831820 -0.90301123  0.776282190  0.30444699 -1.14748923 -1.440690533
#&gt; 74  -0.34719728 -0.80183175 -1.079610620  0.33526170  0.02986996 -1.422982215
#&gt; 75   0.61514177  1.32082067  0.592149208 -2.28425822 -0.05187127 -1.138380472
#&gt; 76   0.68789771  1.03917965  0.326762664 -0.87895358 -0.29070076 -1.560017465
#&gt; 77  -0.09672290  0.55811104 -2.295856107  0.98105921 -0.06218890 -0.468259305
#&gt; 78  -0.74027615 -1.32868715 -0.402928719  0.74271560 -1.07172843  0.467356785
#&gt; 79  -1.16326147 -1.92455679  1.125903449  0.10056759 -1.16839102 -0.146917636
#&gt; 80   0.52833995  0.02269541  1.063092737  0.16902021 -0.19654398  1.624582143
#&gt; 81  -0.07904639 -0.58148841 -1.156393348  0.34330655 -1.23256601  0.424045409
#&gt; 82   1.02657912 -0.22415163 -0.954671006  1.03191632  1.67582582 -0.560888865
#&gt; 83   0.30907212  1.19843419 -0.642356883  1.61580763  0.14981857 -0.229831775
#&gt; 84  -0.34046644 -1.35857871 -0.129691509 -2.05943539  1.10504698  0.994997471
#&gt; 85   0.13103045 -0.02007139  0.295829171  0.71146123 -0.16625956 -0.669661078
#&gt; 86   0.68051453  0.89013344  0.824899518 -0.19750984 -1.62326723  0.071204845
#&gt; 87   0.12433401 -0.02785890 -1.148831250 -1.55998272  0.54408680 -1.183813504
#&gt; 88  -0.87246555 -0.87933866  1.585573941  0.39203385  0.43202330 -0.976633307
#&gt; 89   0.88858779  0.76532204 -0.132846093 -0.10443202 -1.73795791  1.869923666
#&gt; 90   0.99109805 -0.97758855 -0.118899731 -0.30398595  1.32981739 -0.575898320
#&gt; 91   0.17345653  0.53030495  0.119426695 -0.37146423 -0.82576253 -1.019094922
#&gt; 92   0.23095085  0.93490598  0.193494092  1.28880895 -0.74782165 -0.649659900
#&gt; 93  -0.10370354  0.34618828  1.469472441  0.16832416 -2.13353795  1.533933071
#&gt; 94  -0.53466699 -0.73358085 -2.160397828  0.79351401  0.36263912 -0.107787116
#&gt; 95   0.88380862  0.71044321  2.309691146 -1.43665381 -0.23749230  0.169535331
#&gt; 96  -0.08109247 -0.32270804  0.984586572 -2.80920276 -0.91259245  1.008258732
#&gt; 97  -0.06717729 -0.36063854  1.510773654  0.24555120 -0.54637269  1.177163008
#&gt; 98  -0.34213584  0.15515330 -0.044507754 -0.42755197  0.17847832  0.837676659
#&gt; 99  -0.51101709 -1.39090615 -1.153481015  0.32787243 -0.99193808  0.669284255
#&gt; 100  0.35873286  1.37319401  2.294143138  0.24435018 -0.86142982 -0.243659774
#&gt; 101 -0.45132111 -0.86514969  0.538671399  0.94024364  0.45566891  1.129335915
#&gt; 102 -0.02134494 -1.30250885 -0.146357462 -0.13692522 -2.05915568 -0.041590377
#&gt; 103  0.75858908  0.89342076 -0.979218618 -1.85424344  0.16398290  0.914060323
#&gt; 104 -0.34981144 -0.88037666 -1.831172832  1.64373845  0.78839628  0.432991085
#&gt; 105 -0.37632586 -0.41661945  1.870035998 -0.14302351 -1.09377744 -0.936613809
#&gt; 106 -0.08913409 -0.04062916 -1.503020392 -0.52419166 -0.53807090 -0.582746486
#&gt; 107  0.67550059  0.14358965  2.318318542  0.78931815 -0.22432943 -0.090653685
#&gt; 108 -0.33840336  0.09751138 -1.256282212  0.96144097  1.46733421  1.957436095
#&gt; 109 -0.39774616  0.16642969 -0.938503513  1.29350891 -1.60605679  0.843387407
#&gt; 110  1.05740527  1.47631110 -0.526780039 -1.35604594 -0.54841970  0.115736923
#&gt; 111 -1.44354981 -1.54600953 -1.733278053 -0.85199073 -1.12518922  0.051878985
#&gt; 112  1.17984868  1.37092704 -1.078728380 -1.10291173  0.37742996 -0.559855595
#&gt; 113 -0.57377293 -0.30687696 -0.369739572  0.84291478 -0.35847353  0.039211626
#&gt; 114 -0.41396429 -0.17814964  1.418624142 -0.40487444  0.02549246  0.573795451
#&gt; 115  0.75905338  0.84086555 -0.960515383  0.34463034 -0.83657908 -1.722671808
#&gt; 116 -0.81228643 -0.70385466  0.444572597  0.11589273  0.34432991  1.525124902
#&gt; 117 -0.01695148 -0.38034853  0.920231427  0.02267681  1.26276866 -0.035198961
#&gt; 118 -0.13456486 -0.61284745  0.248415976  1.81038765  0.32824879 -0.187316677
#&gt; 119 -1.17201462 -0.84761010 -0.258117777  0.18494050 -0.03846550  0.602229762
#&gt; 120  1.87942283  1.45125747  2.300613151 -0.42790075  0.55285433  0.401261034
#&gt; 
#&gt; $housekeeping
#&gt;      n        mu_i      theta_i
#&gt; 1   38 -0.57220472 -0.110403011
#&gt; 2   52 -0.86076766 -0.994550735
#&gt; 3   34 -0.18484276 -0.479947194
#&gt; 4   32  0.91103776  1.073673824
#&gt; 5   50  0.23879490  0.077083550
#&gt; 6   38  0.07027426  0.295637889
#&gt; 7   38 -0.86301223 -0.698699491
#&gt; 8   26  0.13826583 -0.034774866
#&gt; 9    8 -0.68137984 -0.665516769
#&gt; 10  32  0.41771190  0.518916955
#&gt; 11  30  1.11281162  0.538211463
#&gt; 12  44  0.08613348  0.111778407
#&gt; 13  46 -0.75029639 -0.796466534
#&gt; 14  22 -0.67330868 -0.688752397
#&gt; 15  40 -1.20054114 -1.301720562
#&gt; 16  30  0.39676020  0.732134824
#&gt; 17  60  0.22194567  0.543078167
#&gt; 18  36  0.25191305  0.434458715
#&gt; 19  60  0.71404233  0.880860097
#&gt; 20  36 -0.91604347 -0.759558068
#&gt; 21  58  0.67139140  0.415969976
#&gt; 22  40  1.21947217  1.441140252
#&gt; 23  34  0.33846806  0.205837248
#&gt; 24  40 -0.98449031 -0.882694054
#&gt; 25  64  0.04019071  0.178884132
#&gt; 26  26 -0.35238462 -0.366333503
#&gt; 27  26  0.29862616  0.551341277
#&gt; 28  66  0.39788982  0.350349316
#&gt; 29  48 -0.51541804 -0.692309354
#&gt; 30  14 -0.20976341  0.025731841
#&gt; 31  60  0.08004557  0.260410672
#&gt; 32  52 -0.28224017 -0.189857428
#&gt; 33  20  0.11375327  0.081113592
#&gt; 34  30  0.12853944  0.354045634
#&gt; 35  56 -0.16885040 -0.342201593
#&gt; 36  46  0.15228623 -0.027168989
#&gt; 37  52  0.36221854  0.309529621
#&gt; 38  30 -0.34258665 -0.162344715
#&gt; 39  40  0.33074295 -0.115007554
#&gt; 40  46  0.86270981  0.507714856
#&gt; 41  44  0.16067285  0.094743023
#&gt; 42  32  0.28815795 -0.048047856
#&gt; 43  44 -0.70499609 -0.627156769
#&gt; 44  36 -0.49775103 -0.727641593
#&gt; 45  48  0.78014947  0.585727525
#&gt; 46  14  0.10179700  0.166972621
#&gt; 47  32 -0.19381740 -0.390963946
#&gt; 48  44  0.45980742  0.880290311
#&gt; 49  44 -0.18986946 -0.367066998
#&gt; 50  32  0.37212263  0.502838305
#&gt; 51  54 -0.59159105 -0.726077338
#&gt; 52  36  0.13820953  0.412740339
#&gt; 53  48 -0.17810886 -0.364378784
#&gt; 54  38  0.49386193  0.312374877
#&gt; 55  52 -0.13361682 -0.013720847
#&gt; 56  48  0.24001364  0.594751986
#&gt; 57  30  0.38371137  0.529897650
#&gt; 58  32  0.46972104  0.375083374
#&gt; 59  20 -0.52660630 -0.306364087
#&gt; 60  50  0.50680889  0.060905115
#&gt; 61  48 -0.62708662 -0.480724423
#&gt; 62  42 -0.19029182 -0.087017759
#&gt; 63  16  0.10454441  0.160216409
#&gt; 64  26 -0.06237809  0.005273069
#&gt; 65  36  1.09318897  1.031005329
#&gt; 66  26  0.04101162 -0.301954708
#&gt; 67  34  1.05605102  1.592781611
#&gt; 68  62  0.51717135  0.408599441
#&gt; 69  46 -0.09908660 -0.277930383
#&gt; 70  18 -0.51961479 -0.411171528
#&gt; 71  20 -0.06683205  0.058090708
#&gt; 72  54 -0.29101810 -0.265825394
#&gt; 73  50 -0.45150561 -0.301892062
#&gt; 74  34 -0.40091587 -0.468773592
#&gt; 75  42  0.66041034  0.632834013
#&gt; 76  48  0.51958982  0.606783942
#&gt; 77   8  0.27905552 -0.070952444
#&gt; 78  48 -0.66434357 -0.548251031
#&gt; 79  72 -0.96227839 -1.341979596
#&gt; 80  32  0.01134770  0.285301371
#&gt; 81  44 -0.29074421 -0.192195015
#&gt; 82  30 -0.11207581  0.009216599
#&gt; 83  26  0.59921709  0.213300606
#&gt; 84  68 -0.67928936 -0.546241835
#&gt; 85  18 -0.01003569  0.195122614
#&gt; 86  56  0.44506672  0.629947466
#&gt; 87  38 -0.01392945  0.190647482
#&gt; 88  28 -0.43966933 -0.355124416
#&gt; 89  48  0.38266102  0.541580823
#&gt; 90   8 -0.48879427 -0.539783475
#&gt; 91  50  0.26515247  0.332732908
#&gt; 92  60  0.46745299  0.507476081
#&gt; 93  34  0.17309414  0.135749209
#&gt; 94  32 -0.36679042 -1.005220564
#&gt; 95  22  0.35522160  0.287387874
#&gt; 96  50 -0.16135402 -0.018783716
#&gt; 97  44 -0.18031927 -0.178758180
#&gt; 98  40  0.07757665 -0.196031042
#&gt; 99  32 -0.69545307 -0.664308741
#&gt; 100 40  0.68659701  0.552990749
#&gt; 101 44 -0.43257484 -0.524339492
#&gt; 102 14 -0.65125442 -0.711346529
#&gt; 103 18  0.44671038  0.262839443
#&gt; 104 16 -0.44018833 -0.342319368
#&gt; 105 40 -0.20830972 -0.147333039
#&gt; 106 34 -0.02031458 -0.146168767
#&gt; 107 48  0.07179483  0.228097356
#&gt; 108 36  0.04875569 -0.353462512
#&gt; 109 42  0.08321484  0.217963002
#&gt; 110 48  0.73815555  0.551954362
#&gt; 111 38 -0.77300477 -0.780651379
#&gt; 112 28  0.68546352  0.990646513
#&gt; 113 48 -0.15343848 -0.022634990
#&gt; 114 26 -0.08907482 -0.207256657
#&gt; 115 60  0.42043278  0.824740476
#&gt; 116 58 -0.35192733 -0.547086944
#&gt; 117 44 -0.19017427 -0.311305763
#&gt; 118 60 -0.30642373 -0.014485949
#&gt; 119 24 -0.42380505 -0.371865329
#&gt; 120 36  0.72562874  0.815556112
#&gt; 
#&gt; $tau2_est
#&gt; [1] 0.6674238
#&gt; </div><div class='input'><span class='fu'>SimulateSMD</span>(<span class='kw'>k_train</span> <span class='kw'>=</span> <span class='fl'>50</span>, <span class='kw'>distribution</span> <span class='kw'>=</span> <span class='st'>"bernoulli"</span>)</div><div class='output co'>#&gt; $training
#&gt;            vi           yi X1 X2 X3 X4 X5
#&gt; 1  0.18601400  0.319895727  0  0  1  0  0
#&gt; 2  0.12908127 -0.812082670  0  1  1  0  1
#&gt; 3  0.09927040 -0.798594168  0  1  1  0  0
#&gt; 4  0.11990888  0.726149321  1  1  0  0  1
#&gt; 5  0.18917092  0.478131978  0  1  1  1  1
#&gt; 6  0.17066258  0.324363499  0  1  1  0  0
#&gt; 7  0.08094759  0.176391629  1  1  0  0  0
#&gt; 8  0.07566772  0.634285362  1  0  1  1  1
#&gt; 9  0.07462181  0.007458783  0  0  0  0  1
#&gt; 10 0.11292781  0.229303650  0  0  0  1  0
#&gt; 11 0.17017988  1.160447761  1  0  0  0  0
#&gt; 12 0.08472345 -0.257861306  1  0  0  1  1
#&gt; 13 0.15017861  0.553690447  1  0  1  0  1
#&gt; 14 0.09806810 -0.400214164  1  0  0  0  0
#&gt; 15 0.09356224  0.397827304  0  1  0  0  0
#&gt; 16 0.05172868 -0.156982870  0  0  1  0  1
#&gt; 17 0.22846438  0.399732086  1  1  1  1  1
#&gt; 18 0.08054809 -0.551492525  0  0  0  0  1
#&gt; 19 0.13465681 -0.003788886  0  0  0  0  1
#&gt; 20 0.09712561  0.291156233  0  0  0  0  0
#&gt; 21 0.12137039  0.407408446  0  1  0  0  0
#&gt; 22 0.11344873  0.296651657  0  0  1  0  0
#&gt; 23 0.09458856 -0.494447331  0  1  1  0  0
#&gt; 24 0.08105376 -0.203238217  0  1  0  1  1
#&gt; 25 0.07528058 -0.261855272  0  0  0  1  0
#&gt; 26 0.07810811  0.602189056  0  0  1  0  0
#&gt; 27 0.06303621  0.126754249  1  0  0  0  1
#&gt; 28 0.08284619  0.924873736  1  0  1  0  1
#&gt; 29 0.15626989 -0.207765217  0  0  1  0  1
#&gt; 30 0.14454850  0.117504965  1  1  1  1  0
#&gt; 31 0.06974934 -0.183370252  0  0  0  0  0
#&gt; 32 0.08062792  0.020620029  0  0  0  0  1
#&gt; 33 0.09053356 -0.501793791  0  0  1  1  0
#&gt; 34 0.08096069  0.179921167  0  1  1  1  1
#&gt; 35 0.09033763  0.965690186  1  1  1  0  0
#&gt; 36 0.08576725  0.403139418  1  1  0  1  1
#&gt; 37 0.10022729  0.576980052  1  0  1  1  1
#&gt; 38 0.08529411 -0.344953822  0  0  0  1  0
#&gt; 39 0.11947109  0.210777090  1  1  1  1  0
#&gt; 40 0.10032725  0.583868790  1  0  1  1  0
#&gt; 41 0.16025542 -0.484222913  0  0  0  1  1
#&gt; 42 0.08852121  0.644892130  1  0  1  1  0
#&gt; 43 0.08509067 -0.316664515  0  1  1  0  0
#&gt; 44 0.12186025  0.812395246  1  0  0  0  0
#&gt; 45 0.07298096  0.334883504  1  1  0  1  0
#&gt; 46 0.10632390  0.083222187  0  0  0  0  1
#&gt; 47 0.07853519  0.320709464  1  1  1  0  1
#&gt; 48 0.07221412  0.171255885  0  0  1  1  0
#&gt; 49 0.19206449  1.987575997  1  0  1  1  0
#&gt; 50 0.09269076  0.291655586  1  1  1  0  0
#&gt; 
#&gt; $testing
#&gt;               yi X1 X2 X3 X4 X5
#&gt; 51   1.012904966  1  1  0  0  0
#&gt; 52   0.374774057  1  1  0  1  1
#&gt; 53  -0.455105328  0  1  1  0  0
#&gt; 54  -0.669119888  0  1  1  0  1
#&gt; 55  -0.145538268  0  1  1  1  0
#&gt; 56   0.552748170  0  1  0  0  1
#&gt; 57  -0.458606161  0  1  0  0  1
#&gt; 58  -0.009677788  1  0  1  0  1
#&gt; 59   0.625725427  0  0  0  1  0
#&gt; 60   0.361134730  1  0  1  0  1
#&gt; 61   0.542193010  1  1  0  0  1
#&gt; 62  -0.297937323  0  0  0  0  0
#&gt; 63   0.259755323  1  1  0  1  1
#&gt; 64   0.706061426  1  1  0  1  0
#&gt; 65   0.803470423  1  0  1  1  1
#&gt; 66   0.435566593  0  1  1  0  1
#&gt; 67   0.174003618  1  0  0  1  1
#&gt; 68  -0.261874325  0  0  0  1  1
#&gt; 69  -0.657704227  0  0  0  0  1
#&gt; 70   1.348900101  1  1  0  1  0
#&gt; 71   0.491722164  1  1  1  0  0
#&gt; 72   0.459387290  0  1  1  0  0
#&gt; 73  -0.115919994  0  1  1  0  0
#&gt; 74  -0.692632618  1  1  1  1  0
#&gt; 75   0.626283494  1  0  1  1  1
#&gt; 76  -0.145243748  0  1  1  0  1
#&gt; 77  -0.406112777  1  0  0  0  0
#&gt; 78   0.682455822  0  1  0  0  0
#&gt; 79  -0.406093497  0  1  0  1  0
#&gt; 80  -0.925157959  0  0  0  0  0
#&gt; 81   0.793949861  1  1  0  1  0
#&gt; 82  -0.154417503  0  0  1  0  0
#&gt; 83   0.883598016  1  1  0  0  0
#&gt; 84   0.511118156  1  0  0  1  0
#&gt; 85   0.199453022  1  1  1  1  0
#&gt; 86  -0.186660791  0  1  1  0  1
#&gt; 87  -0.050823065  0  1  1  1  1
#&gt; 88   0.093765476  0  0  1  0  0
#&gt; 89   0.185497677  1  1  1  1  1
#&gt; 90   0.703378447  0  1  1  1  1
#&gt; 91   0.613453650  1  0  1  0  1
#&gt; 92   1.436737422  1  1  1  1  0
#&gt; 93   0.338012947  0  1  0  1  1
#&gt; 94   0.027831583  1  0  0  1  0
#&gt; 95  -0.502460116  0  1  1  0  0
#&gt; 96   0.572883364  1  0  1  1  0
#&gt; 97   0.115567203  0  0  0  1  1
#&gt; 98  -0.075235249  0  1  1  0  0
#&gt; 99   0.759880868  1  0  0  1  1
#&gt; 100  0.272740571  1  0  0  1  0
#&gt; 101  0.841180697  1  1  0  1  1
#&gt; 102 -0.166823745  0  1  1  0  0
#&gt; 103  0.166991396  1  1  1  0  0
#&gt; 104  0.305854368  1  0  0  0  1
#&gt; 105 -0.571938299  0  1  1  0  0
#&gt; 106  0.465967753  1  1  1  0  0
#&gt; 107  0.378830454  1  1  1  1  1
#&gt; 108  0.532428080  1  0  0  1  0
#&gt; 109  0.459242178  1  1  1  1  0
#&gt; 110 -0.363940773  0  1  1  0  1
#&gt; 111  0.122211241  1  1  1  1  0
#&gt; 112 -0.139589124  0  1  1  0  0
#&gt; 113 -0.290900568  0  1  0  1  1
#&gt; 114 -0.140285503  0  0  1  1  0
#&gt; 115 -0.374212002  0  0  1  1  0
#&gt; 116  1.003239234  1  0  0  0  1
#&gt; 117 -0.828637399  0  0  0  0  1
#&gt; 118  0.079694661  1  1  1  1  0
#&gt; 119  0.029921814  0  1  0  1  0
#&gt; 120  0.278153302  1  0  1  1  0
#&gt; 121  0.803054657  1  1  1  1  1
#&gt; 122  0.359287189  0  0  1  0  0
#&gt; 123 -0.482613334  0  1  0  1  0
#&gt; 124 -0.084650908  1  0  0  0  1
#&gt; 125 -0.223874503  0  0  1  1  1
#&gt; 126  0.324810103  1  0  1  1  0
#&gt; 127  0.993530246  1  1  0  1  1
#&gt; 128 -0.003850118  1  0  0  0  0
#&gt; 129  0.152511001  0  1  0  1  0
#&gt; 130 -0.002716635  0  1  1  1  1
#&gt; 131  0.455796944  0  0  1  0  0
#&gt; 132  0.875830915  0  0  1  0  1
#&gt; 133  0.246528549  1  0  0  0  0
#&gt; 134  0.349252780  1  1  1  0  1
#&gt; 135  0.445560610  0  1  1  0  0
#&gt; 136  0.152314692  1  0  1  1  0
#&gt; 137 -0.268616187  1  0  1  0  0
#&gt; 138 -0.787108297  0  0  1  1  0
#&gt; 139  0.051764455  1  1  1  1  1
#&gt; 140  0.044816251  1  1  1  0  1
#&gt; 141 -0.320510163  0  1  1  1  1
#&gt; 142  0.490135511  1  0  1  0  0
#&gt; 143  0.439386341  1  1  0  0  0
#&gt; 144  0.874346062  1  1  0  1  0
#&gt; 145 -0.414164722  1  0  1  1  0
#&gt; 146  1.138882803  1  0  1  1  1
#&gt; 147  0.721229647  1  0  0  1  1
#&gt; 148  0.458024016  1  1  1  0  0
#&gt; 149  0.331885547  0  1  1  1  1
#&gt; 150  0.039939278  0  1  1  1  0
#&gt; 
#&gt; $housekeeping
#&gt;      n mu_i      theta_i
#&gt; 1   20  0.0  0.236457864
#&gt; 2   32  0.0 -0.141724215
#&gt; 3   42  0.0  0.096427145
#&gt; 4   34  0.5  0.694802939
#&gt; 5   20  0.0 -0.239674004
#&gt; 6   22  0.0  0.182219776
#&gt; 7   48  0.5  0.327600385
#&gt; 8   54  0.5  0.424319040
#&gt; 9   52  0.0  0.075423476
#&gt; 10  34  0.0  0.450004325
#&gt; 11  26  0.5  0.683344207
#&gt; 12  46  0.5  0.259912083
#&gt; 13  26  0.5  0.499302746
#&gt; 14  40  0.5  0.285212568
#&gt; 15  42  0.0  0.250052333
#&gt; 16  76  0.0 -0.055583462
#&gt; 17  16  0.5  0.351732483
#&gt; 18  50  0.0 -0.023919158
#&gt; 19  28  0.0  0.249561999
#&gt; 20  40  0.0  0.081809895
#&gt; 21  32  0.0  0.107553678
#&gt; 22  34  0.0  0.445909030
#&gt; 23  42  0.0 -0.290566931
#&gt; 24  48  0.0  0.064367379
#&gt; 25  52  0.0 -0.163375817
#&gt; 26  52  0.0  0.063575485
#&gt; 27  62  0.5  0.473614683
#&gt; 28  52  0.5  0.575362963
#&gt; 29  24  0.0  0.124391768
#&gt; 30  26  0.5  0.240334098
#&gt; 31  56  0.0 -0.209489275
#&gt; 32  48  0.0  0.317906906
#&gt; 33  44  0.0 -0.388176769
#&gt; 34  48  0.0 -0.064779051
#&gt; 35  48  0.5  0.620411220
#&gt; 36  46  0.5  0.414041950
#&gt; 37  40  0.5  0.623995860
#&gt; 38  46  0.0  0.056201448
#&gt; 39  32  0.5  0.319016567
#&gt; 40  40  0.5  0.380514481
#&gt; 41  24  0.0 -0.278942986
#&gt; 42  46  0.5  0.360546875
#&gt; 43  46  0.0 -0.154107231
#&gt; 44  34  0.5  0.758003747
#&gt; 45  54  0.5  0.420998449
#&gt; 46  36  0.0 -0.042406223
#&gt; 47  50  0.5  0.356445304
#&gt; 48  54  0.0 -0.143298699
#&gt; 49  30  0.5  0.621913771
#&gt; 50  42  0.5  0.470757003
#&gt; 51  46  0.5  0.667803624
#&gt; 52  32  0.5  0.275786748
#&gt; 53  66  0.0 -0.032610490
#&gt; 54  28  0.0 -0.261275484
#&gt; 55  20  0.0 -0.001423038
#&gt; 56  42  0.0  0.233271325
#&gt; 57  18  0.0 -0.162185915
#&gt; 58  36  0.5  0.313974053
#&gt; 59  28  0.0 -0.028776824
#&gt; 60  24  0.5  0.881426443
#&gt; 61  54  0.5  0.548352510
#&gt; 62  30  0.0  0.206138982
#&gt; 63  44  0.5  0.256361706
#&gt; 64  44  0.5  0.384669678
#&gt; 65  46  0.5  0.710480564
#&gt; 66  28  0.0 -0.145602348
#&gt; 67  34  0.5  0.394022960
#&gt; 68  40  0.0 -0.139210812
#&gt; 69  50  0.0  0.303460137
#&gt; 70  42  0.5  0.835366692
#&gt; 71  38  0.5  0.803723290
#&gt; 72  34  0.0 -0.007447504
#&gt; 73  44  0.0 -0.198260982
#&gt; 74   8  0.5  0.274965809
#&gt; 75  38  0.5  0.646899407
#&gt; 76  30  0.0  0.049055930
#&gt; 77  46  0.5  0.400398777
#&gt; 78  42  0.0 -0.086547465
#&gt; 79  16  0.0 -0.171420170
#&gt; 80  32  0.0  0.103726034
#&gt; 81  64  0.5  0.965507467
#&gt; 82  36  0.0 -0.024407347
#&gt; 83  40  0.5  0.681232917
#&gt; 84  28  0.5  0.456687037
#&gt; 85  50  0.5  0.113845557
#&gt; 86  44  0.0  0.170289562
#&gt; 87  32  0.0 -0.018967038
#&gt; 88  60  0.0 -0.060745530
#&gt; 89  38  0.5  0.781560507
#&gt; 90   8  0.0 -0.096564537
#&gt; 91  44  0.5  0.652421963
#&gt; 92  26  0.5  0.723186228
#&gt; 93  24  0.0  0.011164221
#&gt; 94  50  0.5  0.044155169
#&gt; 95  44  0.0 -0.001217579
#&gt; 96  30  0.5  0.690616637
#&gt; 97  64  0.0 -0.194712087
#&gt; 98  68  0.0 -0.109612307
#&gt; 99  42  0.5  0.594715999
#&gt; 100 50  0.5  0.472352492
#&gt; 101 32  0.5  0.642653882
#&gt; 102 42  0.0 -0.122421868
#&gt; 103 52  0.5  0.222533065
#&gt; 104 30  0.5  0.406813361
#&gt; 105 42  0.0 -0.001870094
#&gt; 106 58  0.5  0.173989969
#&gt; 107 36  0.5  0.632137309
#&gt; 108 38  0.5  0.849246683
#&gt; 109 64  0.5  0.453708673
#&gt; 110 62  0.0  0.101279461
#&gt; 111 26  0.5  0.403328813
#&gt; 112 48  0.0 -0.149606156
#&gt; 113 22  0.0 -0.382438709
#&gt; 114 56  0.0 -0.227191976
#&gt; 115 44  0.0 -0.135577057
#&gt; 116 30  0.5  0.751593116
#&gt; 117 36  0.0 -0.507693606
#&gt; 118 42  0.5  0.166680013
#&gt; 119  8  0.0  0.040361747
#&gt; 120 48  0.5  0.259946504
#&gt; 121 50  0.5  0.804348627
#&gt; 122 46  0.0  0.203900854
#&gt; 123 52  0.0  0.135880521
#&gt; 124 66  0.5  0.333272677
#&gt; 125 50  0.0 -0.028153004
#&gt; 126 42  0.5  0.398409937
#&gt; 127 42  0.5  0.493365874
#&gt; 128 36  0.5  0.500086117
#&gt; 129 24  0.0  0.149474223
#&gt; 130 30  0.0  0.075034492
#&gt; 131 42  0.0  0.064684728
#&gt; 132 16  0.0  0.023972886
#&gt; 133 60  0.5  0.303310332
#&gt; 134 44  0.5  0.254670557
#&gt; 135 44  0.0  0.395850703
#&gt; 136 40  0.5  0.192303599
#&gt; 137 18  0.5  0.278825155
#&gt; 138 34  0.0 -0.194509557
#&gt; 139 56  0.5  0.623430966
#&gt; 140 32  0.5  0.475578367
#&gt; 141 54  0.0  0.002538519
#&gt; 142 52  0.5  0.549976149
#&gt; 143 50  0.5  0.552210075
#&gt; 144 56  0.5  0.431615110
#&gt; 145 42  0.5  0.508575722
#&gt; 146 18  0.5  0.247560578
#&gt; 147 44  0.5  0.529930265
#&gt; 148 18  0.5  0.479428248
#&gt; 149 40  0.0  0.054100153
#&gt; 150 50  0.0  0.002462566
#&gt; 
#&gt; $tau2_est
#&gt; [1] 0.1328458
#&gt; </div><div class='input'><span class='fu'>SimulateSMD</span>(<span class='kw'>distribution</span> <span class='kw'>=</span> <span class='st'>"bernoulli"</span>, <span class='kw'>model</span> <span class='kw'>=</span> <span class='no'>es</span> * <span class='no'>x</span>[ ,<span class='fl'>1</span>] * <span class='no'>x</span>[ ,<span class='fl'>2</span>])</div><div class='output co'>#&gt; $training
#&gt;            vi           yi X1 X2 X3 X4 X5
#&gt; 1  0.08899914 -0.341713574  0  1  0  0  1
#&gt; 2  0.08483423 -0.276918002  1  0  1  0  0
#&gt; 3  0.09905862  0.787377024  0  0  0  1  1
#&gt; 4  0.18638173  0.342114936  0  0  1  0  0
#&gt; 5  0.12243253  0.483692981  1  0  0  1  0
#&gt; 6  0.14826028  0.454774626  0  0  1  1  1
#&gt; 7  0.10629205  0.068062122  0  0  1  0  0
#&gt; 8  0.09861175  0.451290616  1  1  0  0  0
#&gt; 9  0.13792967  0.428128458  0  0  1  1  0
#&gt; 10 0.13697367  0.360219904  1  0  0  0  1
#&gt; 11 0.14428300  0.001076264  1  0  1  0  0
#&gt; 12 0.05932725 -0.135368361  1  0  1  1  1
#&gt; 13 0.07737572  0.535221797  1  1  1  1  0
#&gt; 14 0.12288741  0.854302613  1  0  1  1  0
#&gt; 15 0.09209183 -0.186419459  0  0  1  1  0
#&gt; 16 0.08702929 -0.527853248  0  1  1  1  1
#&gt; 17 0.20435476  0.914310676  1  0  1  1  0
#&gt; 18 0.11230694  0.101786688  1  1  1  0  1
#&gt; 19 0.06989136  0.222555205  1  1  0  0  0
#&gt; 20 0.41513964  0.770120048  1  1  1  0  0
#&gt; 
#&gt; $testing
#&gt;               yi X1 X2 X3 X4 X5
#&gt; 21   1.395378864  1  1  1  1  0
#&gt; 22  -0.067869107  1  1  0  1  1
#&gt; 23  -0.302146932  1  0  1  1  0
#&gt; 24   0.410507262  1  0  0  0  0
#&gt; 25   0.231038720  1  1  1  1  1
#&gt; 26   0.025904361  1  1  1  0  0
#&gt; 27   0.166662748  1  1  1  1  0
#&gt; 28   0.250770488  0  1  1  0  0
#&gt; 29   0.258631507  1  0  1  0  1
#&gt; 30   0.140105631  0  1  0  0  0
#&gt; 31  -0.057501765  0  1  1  1  1
#&gt; 32   0.173243132  0  0  1  1  1
#&gt; 33  -0.290209083  0  0  1  0  1
#&gt; 34  -0.431566128  0  0  1  1  0
#&gt; 35   0.021351607  1  0  0  1  0
#&gt; 36   0.206182083  1  0  0  1  0
#&gt; 37  -0.232677396  1  0  1  0  0
#&gt; 38   0.048029773  0  0  1  1  1
#&gt; 39   0.484059472  0  1  1  1  1
#&gt; 40   0.125639708  1  1  0  1  0
#&gt; 41   0.675121020  0  1  1  1  1
#&gt; 42   0.287237362  0  1  1  1  0
#&gt; 43  -0.338369412  1  0  1  0  0
#&gt; 44   0.074822076  0  0  0  0  1
#&gt; 45  -0.085615981  0  0  1  1  1
#&gt; 46   0.528662230  1  1  1  1  0
#&gt; 47  -0.104644232  0  0  0  1  0
#&gt; 48   0.309969722  1  1  1  0  0
#&gt; 49  -0.202975543  0  1  1  1  0
#&gt; 50   0.221639650  0  1  0  0  0
#&gt; 51  -0.135852171  0  1  1  0  0
#&gt; 52   0.028421144  0  0  0  0  0
#&gt; 53   0.397051905  0  0  1  1  1
#&gt; 54   0.202422884  1  1  0  1  1
#&gt; 55   0.124097113  0  1  1  0  1
#&gt; 56   0.290230232  1  0  0  1  1
#&gt; 57   0.405228250  1  0  1  0  1
#&gt; 58   0.300594407  1  1  0  1  1
#&gt; 59   0.517528986  0  1  1  0  1
#&gt; 60   1.465508331  1  1  1  0  1
#&gt; 61  -0.482790464  1  0  1  0  1
#&gt; 62  -0.377937818  1  0  1  1  0
#&gt; 63  -0.006511864  1  1  0  1  0
#&gt; 64   0.288785830  0  1  1  1  1
#&gt; 65  -0.229726886  0  0  1  0  1
#&gt; 66   0.253960762  0  0  1  1  0
#&gt; 67   0.045086972  1  1  0  0  0
#&gt; 68   1.629414638  1  1  1  0  0
#&gt; 69   0.310626535  0  0  0  0  1
#&gt; 70  -0.524530601  0  1  0  0  1
#&gt; 71  -0.837544243  0  1  0  1  0
#&gt; 72   0.001063047  1  1  1  0  0
#&gt; 73  -0.512749759  1  0  1  1  0
#&gt; 74   0.492691943  1  0  1  0  0
#&gt; 75   0.338803904  0  1  1  1  1
#&gt; 76  -0.341957673  0  0  1  0  1
#&gt; 77  -0.366096043  0  0  0  1  1
#&gt; 78   0.115912622  0  0  0  1  1
#&gt; 79   0.275936640  1  1  1  0  0
#&gt; 80  -0.013144811  1  0  0  1  0
#&gt; 81   0.379774474  0  0  1  1  1
#&gt; 82   0.287611210  0  1  1  1  1
#&gt; 83  -0.248120632  1  0  0  1  1
#&gt; 84   0.324261855  1  1  0  0  1
#&gt; 85   0.321074450  0  0  1  1  0
#&gt; 86  -0.110752661  0  0  1  0  1
#&gt; 87   0.603823919  1  1  1  0  0
#&gt; 88   0.803019196  1  0  0  0  0
#&gt; 89   0.316675897  0  0  1  1  1
#&gt; 90  -0.470775777  0  1  1  0  0
#&gt; 91   0.090001988  1  1  0  0  0
#&gt; 92   0.124601360  0  0  0  0  0
#&gt; 93   0.677368091  1  1  0  0  0
#&gt; 94   0.325373415  0  0  1  1  0
#&gt; 95  -0.342912459  1  0  1  0  1
#&gt; 96  -0.373029080  0  1  0  1  0
#&gt; 97   0.602362964  1  0  1  0  1
#&gt; 98  -0.083063136  0  0  1  0  1
#&gt; 99  -0.180973084  0  1  0  0  1
#&gt; 100  1.052343474  1  1  1  1  1
#&gt; 101  0.424489594  1  1  0  0  0
#&gt; 102  0.419941381  0  0  1  0  0
#&gt; 103  0.097763076  0  0  1  0  1
#&gt; 104 -0.273573040  0  0  0  0  1
#&gt; 105  0.222844134  0  1  1  0  0
#&gt; 106  0.219034185  0  0  0  1  1
#&gt; 107  1.132880147  1  1  0  0  0
#&gt; 108  0.063847614  0  1  1  1  0
#&gt; 109  0.376217438  1  1  1  1  0
#&gt; 110 -0.118153394  1  0  0  0  0
#&gt; 111  0.380284516  1  1  1  1  0
#&gt; 112 -0.247431475  1  0  1  1  1
#&gt; 113 -0.015349927  1  0  1  1  1
#&gt; 114  0.200829361  0  0  0  0  0
#&gt; 115 -0.736967788  1  0  0  1  0
#&gt; 116  0.560959434  0  1  0  0  1
#&gt; 117 -0.044711686  0  0  0  1  0
#&gt; 118  0.313728749  1  0  0  1  0
#&gt; 119  0.614234855  1  0  1  0  1
#&gt; 120  0.286811516  0  0  0  1  0
#&gt; 
#&gt; $housekeeping
#&gt;      n mu_i       theta_i
#&gt; 1   44  0.0  0.0218125526
#&gt; 2   46  0.0 -0.1400336659
#&gt; 3   42  0.0  0.2903092867
#&gt; 4   20  0.0 -0.1885532832
#&gt; 5   32  0.0 -0.2237167036
#&gt; 6   26  0.0 -0.0318303262
#&gt; 7   36  0.0 -0.1436029033
#&gt; 8   40  0.5  0.5855103000
#&gt; 9   28  0.0  0.2907177529
#&gt; 10  28  0.0  0.0125872729
#&gt; 11  26  0.0 -0.1842569671
#&gt; 12  66  0.0  0.1125469471
#&gt; 13  52  0.5  0.4169749577
#&gt; 14  34  0.0  0.2312223158
#&gt; 15  42  0.0 -0.2127099472
#&gt; 16  46  0.0 -0.3979757558
#&gt; 17  20  0.0 -0.0105729020
#&gt; 18  34  0.5  0.4848077501
#&gt; 19  56  0.5  0.1892874080
#&gt; 20   8  0.5  0.5664453453
#&gt; 21  38  0.5  0.6394519471
#&gt; 22  30  0.5  0.3213496882
#&gt; 23  26  0.0  0.0267255964
#&gt; 24  24  0.0  0.2174360110
#&gt; 25  42  0.5  0.3792154885
#&gt; 26  48  0.5  0.4254662442
#&gt; 27  60  0.5  0.7224911756
#&gt; 28  44  0.0  0.0557765292
#&gt; 29  28  0.0  0.0774486740
#&gt; 30  52  0.0 -0.1829443964
#&gt; 31  46  0.0  0.0464188440
#&gt; 32  56  0.0  0.0495502162
#&gt; 33  14  0.0 -0.0539594794
#&gt; 34  46  0.0 -0.4151037803
#&gt; 35  48  0.0  0.0558204054
#&gt; 36  32  0.0 -0.2076633112
#&gt; 37  54  0.0 -0.0534839040
#&gt; 38  24  0.0 -0.0838029318
#&gt; 39  34  0.0  0.2865577193
#&gt; 40  20  0.5  0.2808178562
#&gt; 41  54  0.0  0.3559495877
#&gt; 42  32  0.0  0.2825776675
#&gt; 43  42  0.0 -0.2057400734
#&gt; 44  54  0.0 -0.0148102239
#&gt; 45  24  0.0 -0.3895915563
#&gt; 46  36  0.5  0.4223380417
#&gt; 47  56  0.0  0.0664195707
#&gt; 48  18  0.5  0.2533554459
#&gt; 49  74  0.0 -0.1311496470
#&gt; 50  82  0.0  0.1352062513
#&gt; 51  54  0.0  0.1108675363
#&gt; 52  46  0.0  0.0361174307
#&gt; 53  32  0.0  0.3182052380
#&gt; 54  16  0.5  0.3002933080
#&gt; 55  44  0.0 -0.2509113668
#&gt; 56  30  0.0  0.5795005516
#&gt; 57  14  0.0  0.2096930659
#&gt; 58  50  0.5  0.1968983139
#&gt; 59  48  0.0  0.3070117044
#&gt; 60  36  0.5  0.6359222265
#&gt; 61  44  0.0 -0.3557027533
#&gt; 62  38  0.0 -0.1609213218
#&gt; 63  50  0.5  0.1303641437
#&gt; 64  32  0.0  0.3234341495
#&gt; 65  40  0.0 -0.0117268317
#&gt; 66  24  0.0  0.0130395502
#&gt; 67  48  0.5  0.4490052228
#&gt; 68  42  0.5  0.9222438706
#&gt; 69  48  0.0 -0.0623635512
#&gt; 70  24  0.0 -0.1890979353
#&gt; 71  26  0.0 -0.0499581918
#&gt; 72  32  0.5  0.0291782348
#&gt; 73  26  0.0 -0.1476377860
#&gt; 74  26  0.0  0.3384559092
#&gt; 75  56  0.0 -0.0496715355
#&gt; 76  16  0.0  0.0446072712
#&gt; 77  26  0.0 -0.4102490769
#&gt; 78  30  0.0  0.1648840286
#&gt; 79  46  0.5  0.5495568846
#&gt; 80  30  0.0 -0.2380674633
#&gt; 81  26  0.0  0.0618427053
#&gt; 82  56  0.0  0.4102666857
#&gt; 83  36  0.0 -0.1108318810
#&gt; 84  38  0.5  0.2173489832
#&gt; 85  48  0.0 -0.1174462182
#&gt; 86  54  0.0  0.1393623175
#&gt; 87  26  0.5  0.3670222764
#&gt; 88  36  0.0 -0.0819854190
#&gt; 89  40  0.0 -0.0240307758
#&gt; 90  46  0.0  0.1293133482
#&gt; 91  46  0.5  0.3058202055
#&gt; 92  46  0.0  0.3124133559
#&gt; 93  40  0.5  0.4429591925
#&gt; 94  42  0.0  0.0758241443
#&gt; 95  58  0.0 -0.1479747575
#&gt; 96  46  0.0  0.0281714361
#&gt; 97  30  0.0  0.2961704360
#&gt; 98  56  0.0 -0.3905419081
#&gt; 99  44  0.0  0.0832442396
#&gt; 100 44  0.5  0.8315698641
#&gt; 101 38  0.5  0.6580547967
#&gt; 102 54  0.0 -0.1371291310
#&gt; 103 56  0.0 -0.2003559292
#&gt; 104 40  0.0  0.0114756443
#&gt; 105 20  0.0  0.1161416058
#&gt; 106 42  0.0  0.3028432146
#&gt; 107 36  0.5  0.6304958577
#&gt; 108 34  0.0 -0.0006682723
#&gt; 109 34  0.5  0.7146986789
#&gt; 110 24  0.0 -0.1710327677
#&gt; 111 22  0.5  0.4508727549
#&gt; 112 48  0.0 -0.2833941434
#&gt; 113 38  0.0 -0.0457327018
#&gt; 114 48  0.0  0.3815720293
#&gt; 115 26  0.0 -0.1168532321
#&gt; 116 46  0.0  0.4633429161
#&gt; 117 52  0.0  0.2012577320
#&gt; 118 52  0.0  0.1859872420
#&gt; 119 56  0.0  0.3185620694
#&gt; 120 56  0.0  0.4965323615
#&gt; 
#&gt; $tau2_est
#&gt; [1] 0.06402135
#&gt; </div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      <li><a href="#value">Value</a></li>
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Caspar J. van Lissa.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


